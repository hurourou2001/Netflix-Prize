{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgcKEj48DWMA",
        "outputId": "4aae92ec-697e-4563-af4a-c9c22cbe3471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/netflix-inc/netflix-prize-data/versions/2\n",
            "Files in the dataset: ['movie_titles.csv', 'combined_data_3.txt', 'combined_data_2.txt', 'combined_data_1.txt', 'combined_data_4.txt', 'probe.txt', 'qualifying.txt', 'README']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "import zipfile\n",
        "\n",
        "# Step 1: Download the dataset using kagglehub\n",
        "path = kagglehub.dataset_download(\"netflix-inc/netflix-prize-data\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Step 2: Verify the downloaded files\n",
        "files = os.listdir(path)\n",
        "print(\"Files in the dataset:\", files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file paths for all combined_data files\n",
        "file_paths = [\n",
        "    \"/content/combined_data_1.txt\",\n",
        "    \"/content/combined_data_2.txt\",\n",
        "]\n",
        "\n",
        "def process_single_file(file_path):\n",
        "    \"\"\"\n",
        "    Processes a single combined_data file and returns a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the combined_data file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the file's data.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    current_movie_id = None\n",
        "\n",
        "    # Read the file line by line\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()  # Remove extra whitespace\n",
        "            if line.endswith(':'):\n",
        "                # Movie ID line\n",
        "                current_movie_id = int(line[:-1])  # Remove ':' and convert to int\n",
        "            else:\n",
        "                # CustomerID, Rating, Date line\n",
        "                customer_id, rating, date = line.split(',')\n",
        "                rows.append([current_movie_id, int(customer_id), int(rating), date])\n",
        "\n",
        "    # Convert rows to a DataFrame\n",
        "    df = pd.DataFrame(rows, columns=['MovieID', 'CustomerID', 'Rating', 'Date'])\n",
        "    return df\n",
        "\n",
        "def combine_files(file_paths):\n",
        "    \"\"\"\n",
        "    Combines data from multiple combined_data files.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list): List of file paths to combine.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A single combined DataFrame.\n",
        "    \"\"\"\n",
        "    data_frames = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "        df = process_single_file(file_path)\n",
        "        data_frames.append(df)\n",
        "\n",
        "    # Concatenate all DataFrames\n",
        "    combined_data = pd.concat(data_frames, ignore_index=True)\n",
        "    return combined_data\n",
        "\n",
        "# Combine all four combined_data files\n",
        "combined_data = combine_files(file_paths)\n",
        "\n",
        "# Display basic information about the combined data\n",
        "print(\"Combined Data Overview:\")\n",
        "print(combined_data.info())\n",
        "print(combined_data.head())\n",
        "\n",
        "# Save the combined data to a CSV file\n",
        "output_file = \"/content/combined_data_all.csv\"  # Adjust path as needed\n",
        "combined_data.to_csv(output_file, index=False)\n",
        "print(f\"Combined data saved to {output_file}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoTC-x_4vXq9",
        "outputId": "15dcd17e-ce10-47e9-f359-ea6cfceec852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/combined_data_1.txt\n",
            "Processing file: /content/combined_data_2.txt\n",
            "Combined Data Overview:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51031355 entries, 0 to 51031354\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Dtype \n",
            "---  ------      ----- \n",
            " 0   MovieID     int64 \n",
            " 1   CustomerID  int64 \n",
            " 2   Rating      int64 \n",
            " 3   Date        object\n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 1.5+ GB\n",
            "None\n",
            "   MovieID  CustomerID  Rating        Date\n",
            "0        1     1488844       3  2005-09-06\n",
            "1        1      822109       5  2005-05-13\n",
            "2        1      885013       4  2005-10-19\n",
            "3        1       30878       4  2005-12-26\n",
            "4        1      823519       3  2004-05-03\n",
            "Combined data saved to /content/combined_data_all.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assume `combined_data` is already loaded\n",
        "# Combined data has columns: ['MovieID', 'CustomerID', 'Rating', 'Date']\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your combined_data.csv file\n",
        "file_path = \"combined_data_all.csv\"\n",
        "combined_data = pd.read_csv(file_path, names=[\"MovieID\", \"CustomerID\", \"Rating\", \"Date\"], header=0)\n",
        "\n",
        "# Step 1: Preprocessing\n",
        "# 1.1 Normalize Ratings\n",
        "global_mean = combined_data['Rating'].mean()\n",
        "combined_data['NormalizedRating'] = combined_data['Rating'] - global_mean\n",
        "\n",
        "# 1.2 Filter Users and Movies\n",
        "user_counts = combined_data['CustomerID'].value_counts()\n",
        "movie_counts = combined_data['MovieID'].value_counts()\n",
        "filtered_data = combined_data[\n",
        "    (combined_data['CustomerID'].isin(user_counts[user_counts >= 10].index)) &\n",
        "    (combined_data['MovieID'].isin(movie_counts[movie_counts >= 5].index))\n",
        "]\n",
        "\n",
        "# 1.3 Transform Dates\n",
        "filtered_data['Date'] = pd.to_datetime(filtered_data['Date'])\n",
        "filtered_data['DaysSinceFirstRating'] = (filtered_data['Date'] - filtered_data['Date'].min()).dt.days\n",
        "filtered_data.drop(columns=['Date'], inplace=True)\n",
        "\n",
        "# Step 2: Splitting the Data\n",
        "# Training: 80%, Validation: 10%, Testing: 10%\n",
        "train_data, temp_data = train_test_split(filtered_data, test_size=0.2, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "# Step 3: Matrix Conversion\n",
        "# User and Movie Encoding\n",
        "train_data['UserEncoded'] = train_data['CustomerID'].astype('category').cat.codes\n",
        "train_data['MovieEncoded'] = train_data['MovieID'].astype('category').cat.codes\n",
        "\n",
        "# Apply same encoding for validation and test sets\n",
        "val_data['UserEncoded'] = val_data['CustomerID'].astype('category').cat.codes\n",
        "val_data['MovieEncoded'] = val_data['MovieID'].astype('category').cat.codes\n",
        "test_data['UserEncoded'] = test_data['CustomerID'].astype('category').cat.codes\n",
        "test_data['MovieEncoded'] = test_data['MovieID'].astype('category').cat.codes\n",
        "\n",
        "# Step 4: Define Features and Targets\n",
        "X_train = train_data[['UserEncoded', 'MovieEncoded', 'DaysSinceFirstRating']]\n",
        "y_train = train_data['NormalizedRating']\n",
        "X_val = val_data[['UserEncoded', 'MovieEncoded', 'DaysSinceFirstRating']]\n",
        "y_val = val_data['NormalizedRating']\n",
        "X_test = test_data[['UserEncoded', 'MovieEncoded', 'DaysSinceFirstRating']]\n",
        "y_test = test_data['NormalizedRating']\n",
        "\n",
        "# Step 5: Regression Model Training\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Validation\n",
        "y_val_pred = regressor.predict(X_val)\n",
        "val_mse = mean_squared_error(y_val, y_val_pred)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "print(\"Validation RMSE:\", val_rmse)\n",
        "\n",
        "# Step 7: Final Evaluation\n",
        "y_test_pred = regressor.predict(X_test)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "print(\"Test RMSE:\", test_rmse)\n",
        "\n",
        "# Step 8: Predicting Ratings\n",
        "example_data = pd.DataFrame({\n",
        "    'UserEncoded': [0, 1],  # Replace with actual user encoding\n",
        "    'MovieEncoded': [0, 2],  # Replace with actual movie encoding\n",
        "    'DaysSinceFirstRating': [5000, 6000]  # Replace with actual days\n",
        "})\n",
        "predicted_ratings = regressor.predict(example_data) + global_mean  # Add global mean to revert normalization\n",
        "print(\"Predicted Ratings for Example Data:\")\n",
        "print(predicted_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByUHU_7ew5kU",
        "outputId": "39833e80-0d63-4443-c8d0-a9034a642c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3575fea55f2d>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data['Date'] = pd.to_datetime(filtered_data['Date'])\n",
            "<ipython-input-5-3575fea55f2d>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data['DaysSinceFirstRating'] = (filtered_data['Date'] - filtered_data['Date'].min()).dt.days\n",
            "<ipython-input-5-3575fea55f2d>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data.drop(columns=['Date'], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 1.0797547607087052\n",
            "Test RMSE: 1.080299223916577\n",
            "Predicted Ratings for Example Data:\n",
            "[4.47356234 4.74571588]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "wgkc-rA6R4VQ"
      }
    }
  ]
}